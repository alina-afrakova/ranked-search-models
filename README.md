# ranked-search-models
Ранжированные модели поиска (векторная и языковая), выдающие наиболее релевантные документы по запросу. Оценка реализованных моделей по мере NDCG.

---
### Общие сведения о реализованных моделях
- **Запросы** – это проанализированные факты из Википедии (файлы из директории `requests`)
- Коллекция собирается из всех упомянутых статей из всех фактов (файлы из директории `articles`)
- **Документы** – это объединенная коллекция предложений из собранных статей всех фактов (полученный программой файл `documents.txt`)
- Термы документов - леммы предложений, полученные с помощью морфологического анализатора библиотеки `pymorphy2` и библиотеки `nltk` с удалением стоп слов (полученный программой файл `lemmas.txt`)

**_Задача:_** Модель должна выдавать первые K (e.g., K = 10) наиболее релевантных документов (предложений) пользователю по заданному запросу. 

---
### Описание алгоритмов моделей
---
#### Векторная модель поиска
- Веса термов в каждом документе расчитываются по формуле:

$w_{ij} = tf-idf(word_i, doc_j) = tf_{ij} * idf_i$ ; i=1,2,3, j=1,2,3,4$

$tf_{ij}$ — кол-во вхождений термина i в документ j

$idf_i$ — обратная подокументная частота i (измеряет непосредственно важность термина i)

$idf_i = \log_{10}{\frac{N} {df}}$,  где $df$ - кол-во документов, где встречается терм i, $N$ - общее число документов

- Рассматриваются 2 варианта для расчета $tf$:
1) $tf = count$
2) $tf = \log_{10} {1+count}$

- Запрос и документы представляются как вектора из подсчитанных весов
- Полученные вектора нормализуются
- Вычисляется косинусная мера между вектором запроса и вектором документа – вес для ранжирования
- Все документы (предложения) ранжируются по мере снижения веса (т.е. по мере сходства с запросом)
- Первые K (e.g., K = 10) документов выдаются пользователю (полученные файлы сохранены в директорию `vect_results`)

---
#### Языковая модель поиска
Языковая модель – математическая модель, которая вычисляет вероятность последовательности слов или условную вероятность следования слова в контексте.

- Общая формулировка языковой модели для информационного поиска (ранжирующая формула):

$p(Q | d) = \prod_{t \in Q} {(1-\lambda) p(t) + \lambda p(t | M_d)}$

$p(t)$ - модель коллекции (= кол-во встреч терма во всех документах / общее кол-во термов)

$p(t | M_d)$ - индивидуальная модель документа (= кол-во встреч терма в документе / кол-во термов в документе)

- Рассматриваются 2 варианта значения $\lambda$:
1) $\lambda = 0.5$
2) $\lambda = 0.9$

- Все документы (предложения) ранжируются по мере снижения вероятности $p(Q | d)$
- Первые K (e.g., K = 10) документов выдаются пользователю (полученные файлы сохранены в директорию `lang_results`)

---
#### Сравнение моделей
- Сравнение результатов языковой и векторной моделей происходит по мере NDCG

NDCG (Mean Average Precision Normalized Discounted Cumulative Gain) - нормализация DCG по отношению к лучшему упорядочению по данному запросу IDCG

$DCG = \sum_{r=1}{\frac{rel_r}{\log (r+1)}}$

IDCG: Для каждого запроса составляется экспертная разметка, т.е. размечаются предложения, насколько они релевантны запросу по трехбалльной шкале {2,1,0}: 2 – предложение содержит полный факт; 1 – предложение содержит часть факта (файл `ideal_documents.txt`)
- Полученные результаты сравнения и соответствующие выводы сохранены в файле `results.txt`

---
### Основные программы
- **`vect_model.py`** - векторная модель поиска
- **`lang_model.py`** - языковая модель поиска
- **`ndcg.py`** - оценивание работы моделей по мере NDCG
