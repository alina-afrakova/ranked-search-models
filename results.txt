Request: Прослушав песню Высоцкого, знаменитый танцор упал на колени перед автором.

NDCG measure for 2 vector models:
tf=count: 0.836
tf=log10(1+count): 0.836

NDCG measure for 2 language models:
lambda=0.5: 0.880
lambda=0.9: 0.922


Request: По мнению искусствоведа, трёхметровая картина российского художника о скотобойне была откликом на гражданскую войну.

NDCG measure for 2 vector models:
tf=count: 0.860
tf=log10(1+count): 0.859

NDCG measure for 2 language models:
lambda=0.5: 0.866
lambda=0.9: 0.929


Request: Джазовая певица (на илл.) с джазовым именем едва не получила «Грэмми» «за лучший вокальный джазовый альбом».

NDCG measure for 2 vector models:
tf=count: 0.760
tf=log10(1+count): 0.760

NDCG measure for 2 language models:
lambda=0.5: 0.760
lambda=0.9: 0.760


----------------------------------------
Mean NDCG for each model (2 vector models and 2 language models):
tf=count: 0.819
tf=log10(1+count): 0.819
lambda=0.5: 0.835
lambda=0.9: 0.870


****************************************
ВЫВОДЫ:
Согласно оценке меры NDCG для каждого запроса языковые модели в среднем показывают более лучшую выдачу, нежели векторные модели, а среди двух языковых моделей выигрывает модель с бОльшим lambda(=0.9), действительно, более высокие значения lambda делает поиск более похожий на булевский, т.е. упор делается на упоминание всех слов в запросе: например, для первого запроса существует немало предложений (документов), где лемма "песня" упоминается 1 или более раз (или предложение-заголовок из одного слова: "Высоцкий"), но при этом сами эти предложения не имеют никакой прямой связи с предложением запроса, предложения же, в которых встречается несколько слов из запроса, как раз обычно и являются самыми релевантными запросу.
Хоть языковая модель и демонстрирует лучшую релевантную выдачу, ее минусом является то, что при подсчете вероятности порождения запроса Q на основе языковой модели документа d происходит немалое кол-во перемножений достаточно маленьких величин (меньших единицы) друг на друга, и в итоге конечная вероятность получается очень малого порядка: например, для первого запроса у первого выданного языковой моделью предложения: p(Q|d)=1.6920165631225273e-21, в то время как для него же у векторной модели: weight=0.305. Для таких маленьких величин (-21 порядка!) требуется бОльшая вычислительная точность, что требует больших вычислительных ресурсов и больших размеров мантиссы.
